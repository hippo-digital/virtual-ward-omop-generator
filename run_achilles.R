#
# Script that prepares a generated dataset for use with the OHDSI Ares tool.
# It requires Achillies, AresIndexer and their dependencies to be installed. 
#
# Two errors/issues are expected:
# 1) The DQD tool will report errors with VISIT tables - see run_dqd.R
# 2) Temporal characterisation cannot be computed if the dataset contains
#    fewer than 36 months of data
#
# The script is modified from that found on the Ares website at:
# https://ohdsi.github.io/Ares/ares-docs.html
#

library(duckdb)
library(DBI)

inputFile <- "dataset.db"
cdmDatabaseSchema <- 'main'
vocabDatabaseSchema <- cdmDatabaseSchema
resultsDatabaseSchema <- "results"
aresDataDirectory <- "./aresDataDir"
cdmVersion <- "5.4"
cdmSourceName <- 'data' # matches the value in the cdm_source table in the duckdb file

# Ensure an empty results schema exists before starting
con <- dbConnect(duckdb(), dbdir = inputFile, read_only = FALSE)
try({
    dbExecute(con, "drop schema results cascade")
})
try({
    dbExecute(con, "create schema results")
})
rm(con)

connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = "duckdb", 
                                            server = inputFile)

Achilles::achilles(connectionDetails = connectionDetails, 
        cdmDatabaseSchema = cdmDatabaseSchema,
        resultsDatabaseSchema = resultsDatabaseSchema, 
        vocabDatabaseSchema = vocabDatabaseSchema,
        outputFolder = "output",
        createTable = T,
        createIndices = F,
        smallCellCount = 0,
)

# The exportToAres function doesn't correctly deal with duckdb returning column
# names that are lower case - monkey patch the querySql function to force
# all column names to upper case for all queries

DC <- getNamespace("DatabaseConnector")
unlockBinding("querySql", DC)
originalQuerySql <- DatabaseConnector::querySql
newQuerySql = function(connection, sql, ...) {
    # cat(file=stderr(), sql, "\n")
    res <- originalQuerySql(connection, sql, ...)
    names(res) <- toupper(names(res))
    # print(head(res, 1))
    res
}
DC$querySql <- newQuerySql


Achilles::exportToAres(
    connectionDetails = connectionDetails,
    cdmDatabaseSchema = cdmDatabaseSchema,
    resultsDatabaseSchema = resultsDatabaseSchema,
    vocabDatabaseSchema = vocabDatabaseSchema,
    outputPath = aresDataDirectory,
)

# remove the monkey patch - it's only required for the code above
DC$querySql <- originalQuerySql

sourceReleaseKey = AresIndexer::getSourceReleaseKey(connectionDetails, cdmDatabaseSchema)
datasourceReleaseOutputFolder <- file.path(aresDataDirectory, sourceReleaseKey)

#Run data quality checks
try({
DataQualityDashboard::executeDqChecks(
    connectionDetails = connectionDetails, 
    cdmDatabaseSchema = cdmDatabaseSchema, 
    resultsDatabaseSchema = resultsDatabaseSchema,
    cdmSourceName = cdmSourceName,
    outputFolder = datasourceReleaseOutputFolder,
    outputFile = "dq-result.json",
    writeToTable = F,
)
})

# Run Achilles temporal characterization - needs 36 months of data... so disabled
outputFile <- file.path(datasourceReleaseOutputFolder, "temporal-characterization.csv")
try ({
Achilles::performTemporalCharacterization(
  connectionDetails = connectionDetails,
  cdmDatabaseSchema = cdmDatabaseSchema,
  resultsDatabaseSchema = resultsDatabaseSchema,
  outputFile = outputFile,
)
})

# Get a list of sources generated by the exportToAres function
list <- list.dirs(aresDataDirectory, recursive = FALSE)

# Augment concept files with data quality details
AresIndexer::augmentConceptFiles(releaseFolder = file.path(aresDataDirectory, cdmSourceName, sourceReleaseKey))
# Export index of all sql functions used in data processing
AresIndexer::buildExportQueryIndex(aresDataDirectory)
# Compare data quality issues with previous source releases (used to display the issue delta)
AresIndexer::augmentDataQualityFiles(sourceFolders = list)
# Create index of quality issues across releases (used to render data quality delta chart)
AresIndexer::buildSourceDataQualityDelta(sourceFolders = list)
# Create index of all available sources and releases
AresIndexer::buildNetworkIndex(list, outputFolder = aresDataDirectory)
# Create quality index across network
AresIndexer::buildDataQualityIndex(list, outputFolder = aresDataDirectory)
# Create index of unmapped source codes across the network
AresIndexer::buildNetworkUnmappedSourceCodeIndex(list, outputFolder = aresDataDirectory)
